#!/usr/bin/env python3
"""
INDRA CoGEx MCP Server - Low-Level Implementation

Uses the low-level MCP SDK instead of FastMCP for better Claude Code compatibility.
All 16 tools migrated from FastMCP to low-level SDK.
"""

import asyncio
import json
import logging
import re
import sys
from typing import Any

import mcp.server.stdio
import mcp.types as types
from mcp.server.lowlevel import NotificationOptions, Server
from mcp.server.models import InitializationOptions

from cogex_mcp.clients.adapter import close_adapter, get_adapter
from cogex_mcp.config import settings
from cogex_mcp.services.cache import get_cache
from cogex_mcp.services.entity_resolver import get_resolver, EntityResolutionError
from cogex_mcp.services.formatter import get_formatter
from cogex_mcp.services.pagination import get_pagination
from cogex_mcp.constants import (
    CHARACTER_LIMIT,
    ENRICHMENT_TIMEOUT,
    STANDARD_QUERY_TIMEOUT,
    ResponseFormat,
)

# Configure logging
logging.basicConfig(
    level=getattr(logging, settings.log_level),
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    if settings.log_format == "text"
    else '{"time":"%(asctime)s","name":"%(name)s","level":"%(levelname)s","message":"%(message)s"}',
    stream=sys.stderr,
)

logger = logging.getLogger(__name__)

# Initialize server
server = Server("cogex_mcp")

# Global state
_adapter = None
_cache = None


async def initialize_backend():
    """Initialize backend connections and services."""
    global _adapter, _cache

    logger.info("ðŸš€ Starting INDRA CoGEx MCP Server (Low-Level)")
    logger.info(
        f"Configuration: primary_backend={settings.has_neo4j_config}, "
        f"fallback={settings.has_rest_fallback}"
    )

    # Initialize client adapter
    _adapter = await get_adapter()
    logger.info("âœ“ Client adapter initialized")

    # Initialize cache
    _cache = get_cache()
    logger.info(
        f"âœ“ Cache initialized: max_size={_cache.max_size}, "
        f"ttl={_cache.ttl_seconds}s, enabled={_cache.enabled}"
    )

    # Get adapter status
    status = _adapter.get_status()
    logger.info(f"Backend status: {status}")
    logger.info("âœ“ Server initialization complete")


async def cleanup_backend():
    """Cleanup backend connections."""
    logger.info("ðŸ›‘ Shutting down INDRA CoGEx MCP Server")

    if _cache and _cache.enabled:
        stats = _cache.get_stats()
        logger.info(f"Final cache stats: {stats}")

    await close_adapter()
    logger.info("âœ“ Connections closed")


@server.list_tools()
async def handle_list_tools() -> list[types.Tool]:
    """List all available tools."""
    return [
        # Tool 1: Disease/Phenotype Query
        types.Tool(
            name="query_disease_or_phenotype",
            description="""Query diseases, phenotypes, and their mechanisms bidirectionally.

This tool supports 3 query modes for comprehensive disease-phenotype exploration:

**Mode 1: disease_to_mechanisms**
Get comprehensive disease profile including associated genes, genetic variants,
phenotypes, drug therapies, and clinical trials.

**Mode 2: phenotype_to_diseases**
Find diseases associated with a specific phenotype. Useful for differential
diagnosis and phenotype-based discovery.

**Mode 3: check_phenotype**
Boolean check: Does a specific disease exhibit a specific phenotype?

Examples:
- Get diabetes profile: mode="disease_to_mechanisms", disease="diabetes mellitus"
- Find diseases with seizures: mode="phenotype_to_diseases", phenotype="HP:0001250"
- Check if Alzheimer's has memory impairment: mode="check_phenotype",
  disease="Alzheimer disease", phenotype="memory impairment"
""",
            inputSchema={
                "type": "object",
                "properties": {
                    "mode": {
                        "type": "string",
                        "enum": [
                            "disease_to_mechanisms",
                            "phenotype_to_diseases",
                            "check_phenotype",
                        ],
                        "description": "Query mode",
                    },
                    "disease": {
                        "type": "string",
                        "description": "Disease name or CURIE (e.g., 'diabetes' or 'mondo:MONDO:0005015')",
                    },
                    "phenotype": {
                        "type": "string",
                        "description": "Phenotype term or CURIE (e.g., 'HP:0001250' or 'seizures')",
                    },
                    "include_genes": {
                        "type": "boolean",
                        "description": "Include associated genes (disease_to_mechanisms only)",
                        "default": True,
                    },
                    "include_variants": {
                        "type": "boolean",
                        "description": "Include genetic variants (disease_to_mechanisms only)",
                        "default": True,
                    },
                    "include_phenotypes": {
                        "type": "boolean",
                        "description": "Include phenotypes (disease_to_mechanisms only)",
                        "default": True,
                    },
                    "include_drugs": {
                        "type": "boolean",
                        "description": "Include drug therapies (disease_to_mechanisms only)",
                        "default": True,
                    },
                    "include_trials": {
                        "type": "boolean",
                        "description": "Include clinical trials (disease_to_mechanisms only)",
                        "default": True,
                    },
                    "response_format": {
                        "type": "string",
                        "enum": ["markdown", "json"],
                        "description": "Output format: 'markdown' (human-readable) or 'json' (machine-readable)",
                        "default": "markdown",
                    },
                    "limit": {
                        "type": "integer",
                        "description": "Maximum results (phenotype_to_diseases mode)",
                        "minimum": 1,
                        "maximum": 100,
                        "default": 20,
                    },
                    "offset": {
                        "type": "integer",
                        "description": "Pagination offset",
                        "minimum": 0,
                        "default": 0,
                    },
                },
                "required": ["mode"],
            },
        ),
        # Tool 2: Gene/Feature Query
        types.Tool(
            name="query_gene_or_feature",
            description="""Query genes and their features bidirectionally.

This tool supports 5 query modes for comprehensive gene-feature exploration:

**Forward Mode (gene â†’ features):**
- gene_to_features: Get all features for a specific gene (expression, GO terms,
  pathways, diseases, domains, variants, phenotypes, codependencies)

**Reverse Modes (feature â†’ genes):**
- tissue_to_genes: Find genes expressed in a specific tissue
- go_to_genes: Find genes annotated with a specific GO term
- domain_to_genes: Find genes containing a specific protein domain
- phenotype_to_genes: Find genes associated with a specific phenotype

Examples:
- Get TP53 profile: mode="gene_to_features", gene="TP53"
- Find brain genes: mode="tissue_to_genes", tissue="brain"
- Find kinases: mode="go_to_genes", go_term="GO:0016301"
""",
            inputSchema={
                "type": "object",
                "properties": {
                    "mode": {
                        "type": "string",
                        "enum": ["gene_to_features", "tissue_to_genes", "go_to_genes", "domain_to_genes", "phenotype_to_genes"],
                        "description": "Query mode",
                    },
                    "gene": {"type": "string", "description": "Gene identifier for gene_to_features"},
                    "tissue": {"type": "string", "description": "Tissue identifier for tissue_to_genes"},
                    "go_term": {"type": "string", "description": "GO term for go_to_genes"},
                    "domain": {"type": "string", "description": "Domain identifier for domain_to_genes"},
                    "phenotype": {"type": "string", "description": "Phenotype identifier for phenotype_to_genes"},
                    "include_expression": {"type": "boolean", "default": True},
                    "include_go_terms": {"type": "boolean", "default": True},
                    "include_pathways": {"type": "boolean", "default": True},
                    "include_diseases": {"type": "boolean", "default": True},
                    "include_domains": {"type": "boolean", "default": False},
                    "include_variants": {"type": "boolean", "default": False},
                    "include_phenotypes": {"type": "boolean", "default": False},
                    "include_codependencies": {"type": "boolean", "default": False},
                    "response_format": {"type": "string", "enum": ["markdown", "json"], "default": "markdown"},
                    "limit": {"type": "integer", "minimum": 1, "maximum": 100, "default": 20},
                    "offset": {"type": "integer", "minimum": 0, "default": 0},
                },
                "required": ["mode"],
            },
        ),
        # Tool 3: Subnetwork Extraction
        types.Tool(
            name="extract_subnetwork",
            description="""Extract mechanistic subnetworks from INDRA knowledge graph.

Query modes:
- direct: Direct edges between genes (Aâ†’B)
- mediated: Two-hop paths (Aâ†’Xâ†’B)
- shared_upstream: Shared regulators (Aâ†Xâ†’B)
- shared_downstream: Shared targets (Aâ†’Xâ†B)
- source_to_targets: One source gene â†’ multiple targets

Examples:
- Direct interactions: mode="direct", genes=["TP53", "MDM2"]
- Find pathway: mode="mediated", genes=["BRCA1", "RAD51"]
- Shared regulators: mode="shared_upstream", genes=["JAK1", "STAT3"]
""",
            inputSchema={
                "type": "object",
                "properties": {
                    "mode": {"type": "string", "enum": ["direct", "mediated", "shared_upstream", "shared_downstream", "source_to_targets"]},
                    "genes": {"type": "array", "items": {"type": "string"}},
                    "source_gene": {"type": "string"},
                    "target_genes": {"type": "array", "items": {"type": "string"}},
                    "tissue_filter": {"type": "string"},
                    "go_filter": {"type": "string"},
                    "include_evidence": {"type": "boolean", "default": False},
                    "statement_types": {"type": "array", "items": {"type": "string"}},
                    "min_evidence_count": {"type": "integer", "default": 1},
                    "min_belief_score": {"type": "number", "default": 0.0},
                    "max_statements": {"type": "integer", "minimum": 1, "maximum": 500, "default": 100},
                    "response_format": {"type": "string", "enum": ["markdown", "json"], "default": "markdown"},
                },
                "required": ["mode"],
            },
        ),
        # Tool 4: Enrichment Analysis
        types.Tool(
            name="enrichment_analysis",
            description="""Perform statistical gene set and pathway enrichment analysis.

Analysis types:
- discrete: Overrepresentation (Fisher's exact test)
- continuous: GSEA with ranked genes
- signed: Directional enrichment (up/down regulation)
- metabolite: Metabolite set enrichment

Sources: go, reactome, wikipathways, indra-upstream, indra-downstream, phenotype

Examples:
- Discrete GO enrichment: analysis_type="discrete", gene_list=["TP53", "MDM2"], source="go"
- GSEA: analysis_type="continuous", ranked_genes={"TP53": 2.5, "MDM2": -1.8}, source="reactome"
""",
            inputSchema={
                "type": "object",
                "properties": {
                    "analysis_type": {"type": "string", "enum": ["discrete", "continuous", "signed", "metabolite"]},
                    "gene_list": {"type": "array", "items": {"type": "string"}},
                    "ranked_genes": {"type": "object"},
                    "background_genes": {"type": "array", "items": {"type": "string"}},
                    "source": {"type": "string", "enum": ["go", "reactome", "wikipathways", "indra-upstream", "indra-downstream", "phenotype"], "default": "go"},
                    "alpha": {"type": "number", "default": 0.05},
                    "correction_method": {"type": "string", "default": "fdr_bh"},
                    "keep_insignificant": {"type": "boolean", "default": False},
                    "permutations": {"type": "integer", "default": 1000},
                    "min_evidence_count": {"type": "integer", "default": 1},
                    "min_belief_score": {"type": "number", "default": 0.0},
                    "response_format": {"type": "string", "enum": ["markdown", "json"], "default": "markdown"},
                },
                "required": ["analysis_type"],
            },
        ),
        # Tool 5: Drug/Effect Query
        types.Tool(
            name="query_drug_or_effect",
            description="""Query drugs and their effects bidirectionally.

Modes:
- drug_to_profile: Drug â†’ comprehensive profile (targets, indications, side effects, trials, cell lines)
- side_effect_to_drugs: Side effect â†’ drugs causing that effect

Examples:
- Get imatinib profile: mode="drug_to_profile", drug="imatinib"
- Find drugs causing nausea: mode="side_effect_to_drugs", side_effect="nausea"
""",
            inputSchema={
                "type": "object",
                "properties": {
                    "mode": {"type": "string", "enum": ["drug_to_profile", "side_effect_to_drugs"]},
                    "drug": {"type": "string"},
                    "side_effect": {"type": "string"},
                    "include_targets": {"type": "boolean", "default": True},
                    "include_indications": {"type": "boolean", "default": True},
                    "include_side_effects": {"type": "boolean", "default": True},
                    "include_trials": {"type": "boolean", "default": False},
                    "include_cell_lines": {"type": "boolean", "default": False},
                    "response_format": {"type": "string", "enum": ["markdown", "json"], "default": "markdown"},
                    "limit": {"type": "integer", "minimum": 1, "maximum": 100, "default": 20},
                    "offset": {"type": "integer", "minimum": 0, "default": 0},
                },
                "required": ["mode"],
            },
        ),
        # Tool 6: Pathway Query
        types.Tool(
            name="query_pathway",
            description="""Query pathway memberships and find shared pathways.

Modes:
- get_genes: Pathway â†’ genes in pathway
- get_pathways: Gene â†’ pathways containing gene
- find_shared: Genes â†’ pathways containing ALL genes
- check_membership: Boolean check if gene is in pathway

Examples:
- Get genes in MAPK: mode="get_genes", pathway="MAPK signaling"
- Get pathways for TP53: mode="get_pathways", gene="TP53"
- Find shared pathways: mode="find_shared", genes=["TP53", "MDM2"]
""",
            inputSchema={
                "type": "object",
                "properties": {
                    "mode": {"type": "string", "enum": ["get_genes", "get_pathways", "find_shared", "check_membership"]},
                    "pathway": {"type": "string"},
                    "gene": {"type": "string"},
                    "genes": {"type": "array", "items": {"type": "string"}},
                    "pathway_source": {"type": "string"},
                    "response_format": {"type": "string", "enum": ["markdown", "json"], "default": "markdown"},
                    "limit": {"type": "integer", "minimum": 1, "maximum": 100, "default": 20},
                    "offset": {"type": "integer", "minimum": 0, "default": 0},
                },
                "required": ["mode"],
            },
        ),
        # Tool 7: Cell Line Query
        types.Tool(
            name="query_cell_line",
            description="""Query cell line data from CCLE and DepMap.

Modes:
- get_properties: Cell line â†’ profile (mutations, CNAs, dependencies, expression)
- get_mutated_genes: Cell line â†’ list of mutated genes
- get_cell_lines_with_mutation: Gene â†’ cell lines with that mutation
- check_mutation: Boolean check if gene is mutated in cell line

Examples:
- Get A549 profile: mode="get_properties", cell_line="A549"
- Find KRAS mutant cell lines: mode="get_cell_lines_with_mutation", gene="KRAS"
""",
            inputSchema={
                "type": "object",
                "properties": {
                    "mode": {"type": "string", "enum": ["get_properties", "get_mutated_genes", "get_cell_lines_with_mutation", "check_mutation"]},
                    "cell_line": {"type": "string"},
                    "gene": {"type": "string"},
                    "include_mutations": {"type": "boolean", "default": True},
                    "include_copy_number": {"type": "boolean", "default": True},
                    "include_dependencies": {"type": "boolean", "default": False},
                    "include_expression": {"type": "boolean", "default": False},
                    "response_format": {"type": "string", "enum": ["markdown", "json"], "default": "markdown"},
                    "limit": {"type": "integer", "minimum": 1, "maximum": 100, "default": 20},
                    "offset": {"type": "integer", "minimum": 0, "default": 0},
                },
                "required": ["mode"],
            },
        ),
        # Tool 8: Clinical Trials Query
        types.Tool(
            name="query_clinical_trials",
            description="""Query ClinicalTrials.gov data for drugs and diseases.

Modes:
- get_for_drug: Drug â†’ clinical trials testing that drug
- get_for_disease: Disease â†’ clinical trials for that disease
- get_by_id: NCT ID â†’ trial details

Examples:
- Find trials for pembrolizumab: mode="get_for_drug", drug="pembrolizumab"
- Find Alzheimer's trials: mode="get_for_disease", disease="Alzheimer's disease"
- Get trial details: mode="get_by_id", trial_id="NCT12345678"
""",
            inputSchema={
                "type": "object",
                "properties": {
                    "mode": {"type": "string", "enum": ["get_for_drug", "get_for_disease", "get_by_id"]},
                    "drug": {"type": "string"},
                    "disease": {"type": "string"},
                    "trial_id": {"type": "string"},
                    "phase": {"type": "array", "items": {"type": "integer"}},
                    "status": {"type": "string"},
                    "response_format": {"type": "string", "enum": ["markdown", "json"], "default": "markdown"},
                    "limit": {"type": "integer", "minimum": 1, "maximum": 100, "default": 20},
                    "offset": {"type": "integer", "minimum": 0, "default": 0},
                },
                "required": ["mode"],
            },
        ),
        # Tool 9: Literature Query
        types.Tool(
            name="query_literature",
            description="""Access PubMed literature and INDRA statement evidence.

Modes:
- get_statements_for_pmid: PMID â†’ INDRA statements from that paper
- get_evidence_for_statement: Statement hash â†’ evidence texts
- search_by_mesh: MeSH terms â†’ publications
- get_statements_by_hashes: Batch retrieve statements by hashes

Examples:
- Get statements from paper: mode="get_statements_for_pmid", pmid="12345678"
- Get evidence: mode="get_evidence_for_statement", statement_hash="abc123"
- Search literature: mode="search_by_mesh", mesh_terms=["autophagy", "cancer"]
""",
            inputSchema={
                "type": "object",
                "properties": {
                    "mode": {"type": "string", "enum": ["get_statements_for_pmid", "get_evidence_for_statement", "search_by_mesh", "get_statements_by_hashes"]},
                    "pmid": {"type": "string"},
                    "statement_hash": {"type": "string"},
                    "mesh_terms": {"type": "array", "items": {"type": "string"}},
                    "statement_hashes": {"type": "array", "items": {"type": "string"}},
                    "include_evidence_text": {"type": "boolean", "default": True},
                    "max_evidence_per_statement": {"type": "integer", "minimum": 1, "maximum": 20, "default": 5},
                    "response_format": {"type": "string", "enum": ["markdown", "json"], "default": "markdown"},
                    "limit": {"type": "integer", "minimum": 1, "maximum": 100, "default": 20},
                    "offset": {"type": "integer", "minimum": 0, "default": 0},
                },
                "required": ["mode"],
            },
        ),
        # Tool 10: Variants Query
        types.Tool(
            name="query_variants",
            description="""Query genetic variants from GWAS Catalog and DisGeNet.

Modes:
- get_for_gene: Gene â†’ variants in/near gene
- get_for_disease: Disease â†’ associated variants
- get_for_phenotype: Phenotype â†’ GWAS hits
- variant_to_genes: Variant (rsID) â†’ nearby genes
- variant_to_phenotypes: Variant â†’ associated phenotypes
- check_association: Check variant-disease association

Examples:
- GWAS hits for APOE: mode="get_for_gene", gene="APOE"
- Alzheimer's variants: mode="get_for_disease", disease="Alzheimer's disease"
- Genes near variant: mode="variant_to_genes", variant="rs7412"
""",
            inputSchema={
                "type": "object",
                "properties": {
                    "mode": {"type": "string", "enum": ["get_for_gene", "get_for_disease", "get_for_phenotype", "variant_to_genes", "variant_to_phenotypes", "check_association"]},
                    "gene": {"type": "string"},
                    "disease": {"type": "string"},
                    "phenotype": {"type": "string"},
                    "variant": {"type": "string"},
                    "min_p_value": {"type": "number"},
                    "max_p_value": {"type": "number", "default": 0.00001},
                    "source": {"type": "string"},
                    "response_format": {"type": "string", "enum": ["markdown", "json"], "default": "markdown"},
                    "limit": {"type": "integer", "minimum": 1, "maximum": 100, "default": 20},
                    "offset": {"type": "integer", "minimum": 0, "default": 0},
                },
                "required": ["mode"],
            },
        ),
        # Tool 11: Identifier Resolution
        types.Tool(
            name="resolve_identifiers",
            description="""Convert identifiers between different biological namespaces.

Common conversions:
- hgnc.symbol â†’ hgnc (gene symbol â†’ HGNC ID)
- hgnc â†’ uniprot (HGNC ID â†’ UniProt ID)
- uniprot â†’ hgnc (UniProt ID â†’ HGNC ID)
- ensembl â†’ hgnc (Ensembl gene â†’ HGNC ID)

Examples:
- Convert symbols to HGNC IDs:
  identifiers=["TP53", "BRCA1"], from_namespace="hgnc.symbol", to_namespace="hgnc"
- Get UniProt IDs:
  identifiers=["11998", "1100"], from_namespace="hgnc", to_namespace="uniprot"
""",
            inputSchema={
                "type": "object",
                "properties": {
                    "identifiers": {"type": "array", "items": {"type": "string"}},
                    "from_namespace": {"type": "string"},
                    "to_namespace": {"type": "string"},
                    "response_format": {"type": "string", "enum": ["markdown", "json"], "default": "markdown"},
                },
                "required": ["identifiers", "from_namespace", "to_namespace"],
            },
        ),
        # Tool 12: Relationship Check
        types.Tool(
            name="check_relationship",
            description="""Check existence of specific relationships between biological entities.

Relationship types:
- gene_in_pathway: Is gene in pathway?
- drug_target: Does drug target gene/protein?
- drug_indication: Is drug indicated for disease?
- drug_side_effect: Does drug cause side effect?
- gene_disease: Is gene associated with disease?
- disease_phenotype: Does disease have phenotype?
- gene_phenotype: Is gene associated with phenotype?
- variant_association: Is variant associated with trait/disease?
- cell_line_mutation: Does cell line have mutation in gene?
- cell_marker: Is gene a marker for cell type?

Examples:
- Is TP53 in p53 signaling? relationship_type="gene_in_pathway", entity1="TP53", entity2="p53 signaling"
- Does imatinib target ABL1? relationship_type="drug_target", entity1="imatinib", entity2="ABL1"
""",
            inputSchema={
                "type": "object",
                "properties": {
                    "relationship_type": {"type": "string", "enum": ["gene_in_pathway", "drug_target", "drug_indication", "drug_side_effect", "gene_disease", "disease_phenotype", "gene_phenotype", "variant_association", "cell_line_mutation", "cell_marker"]},
                    "entity1": {"type": "string"},
                    "entity2": {"type": "string"},
                    "response_format": {"type": "string", "enum": ["markdown", "json"], "default": "markdown"},
                },
                "required": ["relationship_type", "entity1", "entity2"],
            },
        ),
        # Tool 13: Ontology Hierarchy
        types.Tool(
            name="get_ontology_hierarchy",
            description="""Navigate ontology hierarchies (GO, HPO, MONDO, etc.).

Modes:
- parents: Get parent/ancestor terms
- children: Get child/descendant terms
- both: Get both parents and children

Examples:
- Get parents of apoptosis: term="GO:0006915", direction="parents", max_depth=3
- Get children: term="GO:0009987", direction="children", max_depth=2
- Full hierarchy: term="apoptosis", direction="both", max_depth=2
""",
            inputSchema={
                "type": "object",
                "properties": {
                    "term": {"type": "string"},
                    "direction": {"type": "string", "enum": ["parents", "children", "both"]},
                    "max_depth": {"type": "integer", "minimum": 1, "maximum": 5, "default": 2},
                    "response_format": {"type": "string", "enum": ["markdown", "json"], "default": "markdown"},
                },
                "required": ["term", "direction"],
            },
        ),
        # Tool 14: Cell Markers Query
        types.Tool(
            name="query_cell_markers",
            description="""Query CellMarker database for cell type markers.

Modes:
- get_markers: Cell type â†’ marker genes
- get_cell_types: Marker gene â†’ cell types
- check_marker: Boolean check if gene is a marker for cell type

Examples:
- Get markers for T cells: mode="get_markers", cell_type="T cell"
- Find cell types expressing CD4: mode="get_cell_types", marker="CD4"
- Check if CD8A is T cell marker: mode="check_marker", cell_type="T cell", marker="CD8A"
""",
            inputSchema={
                "type": "object",
                "properties": {
                    "mode": {"type": "string", "enum": ["get_markers", "get_cell_types", "check_marker"]},
                    "cell_type": {"type": "string"},
                    "marker": {"type": "string"},
                    "tissue": {"type": "string"},
                    "species": {"type": "string", "default": "human"},
                    "response_format": {"type": "string", "enum": ["markdown", "json"], "default": "markdown"},
                    "limit": {"type": "integer", "minimum": 1, "maximum": 100, "default": 20},
                    "offset": {"type": "integer", "minimum": 0, "default": 0},
                },
                "required": ["mode"],
            },
        ),
        # Tool 15: Kinase Enrichment
        types.Tool(
            name="analyze_kinase_enrichment",
            description="""Predict upstream kinases from phosphoproteomics data.

Analyzes phosphorylation sites to identify enriched kinase activities.

Input format: GENE_RESIDUE_POSITION (e.g., TP53_S15, MAPK1_T185, EGFR_Y1068)
- S = serine, T = threonine, Y = tyrosine

Examples:
- Basic analysis: phosphosites=["TP53_S15", "TP53_S20", "MDM2_S166"]
- With background: phosphosites=[...], background=["GENE1_S10", ...]
""",
            inputSchema={
                "type": "object",
                "properties": {
                    "phosphosites": {"type": "array", "items": {"type": "string"}},
                    "background": {"type": "array", "items": {"type": "string"}},
                    "alpha": {"type": "number", "default": 0.05},
                    "correction_method": {"type": "string", "default": "fdr_bh"},
                    "response_format": {"type": "string", "enum": ["markdown", "json"], "default": "markdown"},
                },
                "required": ["phosphosites"],
            },
        ),
        # Tool 16: Protein Functions Query
        types.Tool(
            name="query_protein_functions",
            description="""Query enzyme activities and protein function types.

Modes:
- gene_to_activities: Gene â†’ enzyme activities
- activity_to_genes: Activity â†’ genes (paginated)
- check_activity: Boolean check if gene has specific activity
- check_function_types: Batch check kinase/phosphatase/TF for gene lists

Function types: kinase, phosphatase, transcription_factor

Examples:
- Get activities for EGFR: mode="gene_to_activities", gene="EGFR"
- Find all kinases: mode="activity_to_genes", enzyme_activity="kinase"
- Batch check: mode="check_function_types", genes=["TP53", "EGFR"], function_types=["kinase", "transcription_factor"]
""",
            inputSchema={
                "type": "object",
                "properties": {
                    "mode": {"type": "string", "enum": ["gene_to_activities", "activity_to_genes", "check_activity", "check_function_types"]},
                    "gene": {"type": "string"},
                    "genes": {"type": "array", "items": {"type": "string"}},
                    "enzyme_activity": {"type": "string"},
                    "function_types": {"type": "array", "items": {"type": "string"}},
                    "response_format": {"type": "string", "enum": ["markdown", "json"], "default": "markdown"},
                    "limit": {"type": "integer", "minimum": 1, "maximum": 100, "default": 20},
                    "offset": {"type": "integer", "minimum": 0, "default": 0},
                },
                "required": ["mode"],
            },
        ),
    ]


@server.call_tool()
async def handle_call_tool(
    name: str, arguments: dict[str, Any]
) -> list[types.TextContent]:
    """Handle tool calls."""
    try:
        # Route to appropriate handler
        if name == "query_disease_or_phenotype":
            return await _handle_disease_phenotype_query(arguments)
        elif name == "query_gene_or_feature":
            return await _handle_gene_feature_query(arguments)
        elif name == "extract_subnetwork":
            return await _handle_subnetwork_extraction(arguments)
        elif name == "enrichment_analysis":
            return await _handle_enrichment_analysis(arguments)
        elif name == "query_drug_or_effect":
            return await _handle_drug_effect_query(arguments)
        elif name == "query_pathway":
            return await _handle_pathway_query(arguments)
        elif name == "query_cell_line":
            return await _handle_cell_line_query(arguments)
        elif name == "query_clinical_trials":
            return await _handle_clinical_trials_query(arguments)
        elif name == "query_literature":
            return await _handle_literature_query(arguments)
        elif name == "query_variants":
            return await _handle_variants_query(arguments)
        elif name == "resolve_identifiers":
            return await _handle_identifier_resolution(arguments)
        elif name == "check_relationship":
            return await _handle_relationship_check(arguments)
        elif name == "get_ontology_hierarchy":
            return await _handle_ontology_hierarchy(arguments)
        elif name == "query_cell_markers":
            return await _handle_cell_markers_query(arguments)
        elif name == "analyze_kinase_enrichment":
            return await _handle_kinase_enrichment(arguments)
        elif name == "query_protein_functions":
            return await _handle_protein_functions_query(arguments)
        else:
            raise ValueError(f"Unknown tool: {name}")
    except Exception as e:
        logger.error(f"Tool error in {name}: {e}", exc_info=True)
        return [types.TextContent(
            type="text",
            text=f"Error: {str(e)}"
        )]


# ============================================================================
# Tool 1: Disease/Phenotype Query
# ============================================================================

async def _handle_disease_phenotype_query(args: dict[str, Any]) -> list[types.TextContent]:
    """Handle disease/phenotype query."""
    mode = args.get("mode")
    disease = args.get("disease")
    phenotype = args.get("phenotype")
    response_format = args.get("response_format", "markdown")

    # Route to appropriate handler based on mode
    if mode == "disease_to_mechanisms":
        if not disease:
            return [types.TextContent(
                type="text",
                text="Error: disease parameter required for disease_to_mechanisms mode"
            )]
        result = await _disease_to_mechanisms(args)
    elif mode == "phenotype_to_diseases":
        if not phenotype:
            return [types.TextContent(
                type="text",
                text="Error: phenotype parameter required for phenotype_to_diseases mode"
            )]
        result = await _phenotype_to_diseases(args)
    elif mode == "check_phenotype":
        if not disease or not phenotype:
            return [types.TextContent(
                type="text",
                text="Error: both disease and phenotype parameters required for check_phenotype mode"
            )]
        result = await _check_phenotype(args)
    else:
        return [types.TextContent(
            type="text",
            text=f"Error: Unknown query mode '{mode}'"
        )]

    # Format response
    formatter = get_formatter()
    response = formatter.format_response(
        data=result,
        format_type=response_format,
        max_chars=CHARACTER_LIMIT,
    )

    return [types.TextContent(type="text", text=response)]


async def _disease_to_mechanisms(args: dict[str, Any]) -> dict[str, Any]:
    """Get comprehensive disease profile with all molecular mechanisms."""
    disease_input = args["disease"]

    # Resolve disease identifier
    resolver = get_resolver()
    disease_ref = await resolver.resolve_disease(disease_input)

    result = {
        "disease": {
            "name": disease_ref.name,
            "curie": disease_ref.curie,
            "namespace": disease_ref.namespace,
            "identifier": disease_ref.identifier,
        }
    }

    adapter = await get_adapter()

    # Fetch requested features
    if args.get("include_genes", True):
        gene_data = await adapter.query(
            "get_genes_for_disease",
            disease_id=disease_ref.curie,
            timeout=STANDARD_QUERY_TIMEOUT,
        )
        result["genes"] = _parse_gene_associations(gene_data)

    if args.get("include_variants", True):
        variant_data = await adapter.query(
            "get_variants_for_disease",
            disease_id=disease_ref.curie,
            timeout=STANDARD_QUERY_TIMEOUT,
        )
        result["variants"] = _parse_variant_associations(variant_data)

    if args.get("include_phenotypes", True):
        phenotype_data = await adapter.query(
            "get_phenotypes_for_disease",
            disease_id=disease_ref.curie,
            timeout=STANDARD_QUERY_TIMEOUT,
        )
        result["phenotypes"] = _parse_phenotype_associations(phenotype_data)

    if args.get("include_drugs", True):
        drug_data = await adapter.query(
            "get_drugs_for_indication",
            disease_id=disease_ref.curie,
            timeout=STANDARD_QUERY_TIMEOUT,
        )
        result["drugs"] = _parse_drug_therapies(drug_data)

    if args.get("include_trials", True):
        trial_data = await adapter.query(
            "get_trials_for_disease",
            disease_id=disease_ref.curie,
            timeout=STANDARD_QUERY_TIMEOUT,
        )
        result["trials"] = _parse_clinical_trials(trial_data)

    return result


async def _phenotype_to_diseases(args: dict[str, Any]) -> dict[str, Any]:
    """Find diseases associated with a specific phenotype."""
    phenotype_id = args["phenotype"]
    limit = args.get("limit", 20)
    offset = args.get("offset", 0)

    adapter = await get_adapter()
    disease_data = await adapter.query(
        "get_diseases_for_phenotype",
        phenotype_id=phenotype_id,
        limit=limit,
        offset=offset,
        timeout=STANDARD_QUERY_TIMEOUT,
    )

    diseases = _parse_disease_list(disease_data)

    return {
        "diseases": diseases,
        "pagination": {
            "total_count": disease_data.get("total_count", len(diseases)),
            "count": len(diseases),
            "offset": offset,
            "limit": limit,
            "has_more": disease_data.get("total_count", len(diseases)) > offset + len(diseases),
        },
    }


async def _check_phenotype(args: dict[str, Any]) -> dict[str, Any]:
    """Boolean check: Does disease have specific phenotype?"""
    disease_input = args["disease"]
    phenotype_id = args["phenotype"]

    # Resolve disease identifier
    resolver = get_resolver()
    disease_ref = await resolver.resolve_disease(disease_input)

    adapter = await get_adapter()
    check_data = await adapter.query(
        "has_phenotype",
        disease_id=disease_ref.curie,
        phenotype_id=phenotype_id,
        timeout=STANDARD_QUERY_TIMEOUT,
    )

    has_phenotype = check_data.get("result", False) if check_data.get("success") else False

    return {
        "has_phenotype": has_phenotype,
        "disease": {
            "name": disease_ref.name,
            "curie": disease_ref.curie,
            "namespace": disease_ref.namespace,
            "identifier": disease_ref.identifier,
        },
        "phenotype": {
            "name": phenotype_id,
            "curie": phenotype_id if ":" in phenotype_id else f"unknown:{phenotype_id}",
        },
    }


# Data parsing helpers for Tool 1
def _parse_gene_associations(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse gene-disease associations from backend response."""
    if not data.get("success") or not data.get("records"):
        return []

    associations = []
    for record in data["records"]:
        associations.append({
            "gene": {
                "name": record.get("gene", "Unknown"),
                "curie": record.get("gene_id", "unknown:unknown"),
            },
            "score": record.get("score", 0.0),
            "evidence_count": record.get("evidence_count", 0),
            "sources": record.get("sources", []),
        })

    return associations


def _parse_variant_associations(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse variant-disease associations from backend response."""
    if not data.get("success") or not data.get("records"):
        return []

    variants = []
    for record in data["records"]:
        variants.append({
            "variant": record.get("rsid", "unknown"),
            "gene": {
                "name": record.get("gene", "Unknown"),
                "curie": record.get("gene_id", "unknown:unknown"),
            },
            "p_value": record.get("p_value"),
            "odds_ratio": record.get("odds_ratio"),
            "trait": record.get("trait"),
        })

    return variants


def _parse_phenotype_associations(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse disease-phenotype associations from backend response."""
    if not data.get("success") or not data.get("records"):
        return []

    phenotypes = []
    for record in data["records"]:
        phenotypes.append({
            "phenotype": {
                "name": record.get("phenotype", "Unknown"),
                "curie": record.get("phenotype_id", "unknown:unknown"),
            },
            "frequency": record.get("frequency"),
            "evidence_count": record.get("evidence_count", 0),
        })

    return phenotypes


def _parse_drug_therapies(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse drug therapy data from backend response."""
    if not data.get("success") or not data.get("records"):
        return []

    drugs = []
    for record in data["records"]:
        drugs.append({
            "drug": {
                "name": record.get("drug", "Unknown"),
                "curie": record.get("drug_id", "unknown:unknown"),
            },
            "indication_type": record.get("indication_type", "unknown"),
            "max_phase": record.get("max_phase"),
            "status": record.get("status"),
        })

    return drugs


def _parse_clinical_trials(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse clinical trial data from backend response."""
    if not data.get("success") or not data.get("records"):
        return []

    trials = []
    for record in data["records"]:
        nct_id = record.get("nct_id", "unknown")
        trials.append({
            "nct_id": nct_id,
            "title": record.get("title", "Unknown Trial"),
            "phase": record.get("phase"),
            "status": record.get("status", "unknown"),
            "url": f"https://clinicaltrials.gov/ct2/show/{nct_id}",
        })

    return trials


def _parse_disease_list(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse disease list from backend response."""
    if not data.get("success") or not data.get("records"):
        return []

    diseases = []
    for record in data["records"]:
        diseases.append({
            "name": record.get("disease", "Unknown"),
            "curie": record.get("disease_id", "unknown:unknown"),
            "description": record.get("description"),
        })

    return diseases


# ============================================================================
# Tool 2: Gene/Feature Query - Mode Handlers
# ============================================================================

async def _gene_to_features(args: dict[str, Any]) -> dict[str, Any]:
    """Get comprehensive gene profile with all requested features."""
    gene_input = args["gene"]

    # Resolve gene identifier
    resolver = get_resolver()
    gene = await resolver.resolve_gene(gene_input)

    adapter = await get_adapter()
    result = {
        "gene": {
            "name": gene.name,
            "curie": gene.curie,
            "namespace": gene.namespace,
            "identifier": gene.identifier,
        },
    }

    # Fetch requested features
    if args.get("include_expression", True):
        expression_data = await adapter.query(
            "get_tissues_for_gene",
            gene_id=gene.curie,
            timeout=STANDARD_QUERY_TIMEOUT,
        )
        result["expression"] = _parse_expression_data(expression_data)

    if args.get("include_go_terms", True):
        go_data = await adapter.query(
            "get_go_terms_for_gene",
            gene_id=gene.curie,
            timeout=STANDARD_QUERY_TIMEOUT,
        )
        result["go_terms"] = _parse_go_annotations(go_data)

    if args.get("include_pathways", True):
        pathway_data = await adapter.query(
            "get_pathways_for_gene",
            gene_id=gene.curie,
            timeout=STANDARD_QUERY_TIMEOUT,
        )
        result["pathways"] = _parse_pathway_memberships(pathway_data)

    if args.get("include_diseases", True):
        disease_data = await adapter.query(
            "get_diseases_for_gene",
            gene_id=gene.curie,
            timeout=STANDARD_QUERY_TIMEOUT,
        )
        result["diseases"] = _parse_disease_associations(disease_data)

    # Optional features
    if args.get("include_domains", False):
        result["domains"] = []

    if args.get("include_variants", False):
        result["variants"] = []

    if args.get("include_phenotypes", False):
        result["phenotypes"] = []

    if args.get("include_codependencies", False):
        result["codependencies"] = []

    return result


async def _tissue_to_genes(args: dict[str, Any]) -> dict[str, Any]:
    """Find genes expressed in a specific tissue."""
    tissue_input = args["tissue"]
    limit = args.get("limit", 20)
    offset = args.get("offset", 0)

    # For now, accept tissue name directly
    tissue_id = tissue_input if isinstance(tissue_input, str) else tissue_input[1]

    adapter = await get_adapter()
    gene_data = await adapter.query(
        "get_genes_in_tissue",
        tissue_id=tissue_id,
        limit=limit,
        offset=offset,
        timeout=STANDARD_QUERY_TIMEOUT,
    )

    genes = _parse_gene_list(gene_data)

    pagination_service = get_pagination()
    pagination = pagination_service.paginate(
        items=genes,
        total_count=gene_data.get("total_count", len(genes)),
        offset=offset,
        limit=limit,
    )

    return {
        "genes": genes,
        "pagination": pagination.model_dump(),
    }


async def _go_to_genes(args: dict[str, Any]) -> dict[str, Any]:
    """Find genes annotated with a specific GO term."""
    go_input = args["go_term"]
    limit = args.get("limit", 20)
    offset = args.get("offset", 0)

    go_id = go_input if isinstance(go_input, str) else go_input[1]

    adapter = await get_adapter()
    gene_data = await adapter.query(
        "get_genes_for_go_term",
        go_id=go_id,
        limit=limit,
        offset=offset,
        timeout=STANDARD_QUERY_TIMEOUT,
    )

    genes = _parse_gene_list(gene_data)

    pagination_service = get_pagination()
    pagination = pagination_service.paginate(
        items=genes,
        total_count=gene_data.get("total_count", len(genes)),
        offset=offset,
        limit=limit,
    )

    return {
        "genes": genes,
        "pagination": pagination.model_dump(),
    }


async def _domain_to_genes(args: dict[str, Any]) -> dict[str, Any]:
    """Find genes containing a specific protein domain."""
    limit = args.get("limit", 20)
    offset = args.get("offset", 0)

    return {
        "genes": [],
        "pagination": {
            "total_count": 0,
            "count": 0,
            "offset": offset,
            "limit": limit,
            "has_more": False,
            "next_offset": None,
        },
        "note": "Domain queries not yet implemented in backend",
    }


async def _phenotype_to_genes(args: dict[str, Any]) -> dict[str, Any]:
    """Find genes associated with a specific phenotype."""
    limit = args.get("limit", 20)
    offset = args.get("offset", 0)

    return {
        "genes": [],
        "pagination": {
            "total_count": 0,
            "count": 0,
            "offset": offset,
            "limit": limit,
            "has_more": False,
            "next_offset": None,
        },
        "note": "Phenotype queries not yet implemented in backend",
    }


# Data parsing helpers for Tool 2
def _parse_expression_data(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse tissue expression data from backend response."""
    if not data.get("success") or not data.get("records"):
        return []

    expressions = []
    for record in data["records"]:
        expressions.append({
            "tissue": {
                "name": record.get("tissue", "Unknown"),
                "curie": record.get("tissue_id", "unknown:unknown"),
                "namespace": "uberon",
                "identifier": record.get("tissue_id", "unknown"),
            },
            "confidence": record.get("confidence", "unknown"),
            "evidence_count": record.get("evidence_count", 0),
        })

    return expressions


def _parse_go_annotations(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse GO annotations from backend response."""
    if not data.get("success") or not data.get("records"):
        return []

    annotations = []
    for record in data["records"]:
        annotations.append({
            "go_term": {
                "name": record.get("term", "Unknown"),
                "curie": record.get("go_id", "unknown:unknown"),
                "namespace": "go",
                "identifier": record.get("go_id", "unknown"),
            },
            "aspect": record.get("aspect", "unknown"),
            "evidence_code": record.get("evidence_code", "N/A"),
        })

    return annotations


def _parse_pathway_memberships(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse pathway memberships from backend response."""
    if not data.get("success") or not data.get("records"):
        return []

    pathways = []
    for record in data["records"]:
        pathways.append({
            "pathway": {
                "name": record.get("pathway", "Unknown"),
                "curie": record.get("pathway_id", "unknown:unknown"),
                "namespace": record.get("source", "unknown"),
                "identifier": record.get("pathway_id", "unknown"),
            },
            "source": record.get("source", "unknown"),
        })

    return pathways


def _parse_gene_list(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse gene list from backend response."""
    if not data.get("success") or not data.get("records"):
        return []

    genes = []
    for record in data["records"]:
        genes.append({
            "name": record.get("gene", "Unknown"),
            "curie": record.get("gene_id", "unknown:unknown"),
            "namespace": "hgnc",
            "identifier": record.get("gene_id", "unknown"),
        })

    return genes


# ============================================================================
# Tool Handler Stubs (implementations would continue similarly for all tools)
# ============================================================================

async def _handle_gene_feature_query(args: dict[str, Any]) -> list[types.TextContent]:
    """Handle gene/feature query - Tool 2."""
    mode = args.get("mode")
    response_format = args.get("response_format", "markdown")

    # Route to appropriate handler based on mode
    if mode == "gene_to_features":
        if not args.get("gene"):
            return [types.TextContent(
                type="text",
                text="Error: gene parameter required for gene_to_features mode"
            )]
        result = await _gene_to_features(args)
    elif mode == "tissue_to_genes":
        if not args.get("tissue"):
            return [types.TextContent(
                type="text",
                text="Error: tissue parameter required for tissue_to_genes mode"
            )]
        result = await _tissue_to_genes(args)
    elif mode == "go_to_genes":
        if not args.get("go_term"):
            return [types.TextContent(
                type="text",
                text="Error: go_term parameter required for go_to_genes mode"
            )]
        result = await _go_to_genes(args)
    elif mode == "domain_to_genes":
        if not args.get("domain"):
            return [types.TextContent(
                type="text",
                text="Error: domain parameter required for domain_to_genes mode"
            )]
        result = await _domain_to_genes(args)
    elif mode == "phenotype_to_genes":
        if not args.get("phenotype"):
            return [types.TextContent(
                type="text",
                text="Error: phenotype parameter required for phenotype_to_genes mode"
            )]
        result = await _phenotype_to_genes(args)
    else:
        return [types.TextContent(
            type="text",
            text=f"Error: Unknown query mode '{mode}'"
        )]

    # Format response
    formatter = get_formatter()
    response = formatter.format_response(
        data=result,
        format_type=response_format,
        max_chars=CHARACTER_LIMIT,
    )

    return [types.TextContent(type="text", text=response)]


async def _handle_subnetwork_extraction(args: dict[str, Any]) -> list[types.TextContent]:
    """Handle subnetwork extraction - Tool 3."""
    try:
        mode = args.get("mode")
        response_format = args.get("response_format", "markdown")

        # Route to appropriate handler based on mode
        if mode == "direct":
            if not args.get("genes") or len(args.get("genes", [])) < 2:
                return [types.TextContent(
                    type="text",
                    text="Error: direct mode requires at least 2 genes"
                )]
            result = await _extract_direct(args)
        elif mode == "mediated":
            if not args.get("genes") or len(args.get("genes", [])) < 2:
                return [types.TextContent(
                    type="text",
                    text="Error: mediated mode requires at least 2 genes"
                )]
            result = await _extract_mediated(args)
        elif mode == "shared_upstream":
            if not args.get("genes") or len(args.get("genes", [])) < 2:
                return [types.TextContent(
                    type="text",
                    text="Error: shared_upstream mode requires at least 2 genes"
                )]
            result = await _extract_shared_upstream(args)
        elif mode == "shared_downstream":
            if not args.get("genes") or len(args.get("genes", [])) < 2:
                return [types.TextContent(
                    type="text",
                    text="Error: shared_downstream mode requires at least 2 genes"
                )]
            result = await _extract_shared_downstream(args)
        elif mode == "source_to_targets":
            if not args.get("source_gene"):
                return [types.TextContent(
                    type="text",
                    text="Error: source_to_targets mode requires source_gene parameter"
                )]
            result = await _extract_source_to_targets(args)
        else:
            return [types.TextContent(
                type="text",
                text=f"Error: Unknown subnetwork mode '{mode}'"
            )]

        # Format response
        formatter = get_formatter()
        response = formatter.format_response(
            data=result,
            format_type=response_format,
            max_chars=CHARACTER_LIMIT,
        )

        return [types.TextContent(type="text", text=response)]

    except EntityResolutionError as e:
        logger.warning(f"Entity resolution error: {e}")
        return [types.TextContent(type="text", text=f"Error: {str(e)}")]
    except Exception as e:
        logger.error(f"Tool error: {e}", exc_info=True)
        return [types.TextContent(type="text", text=f"Error: Unexpected error occurred. {str(e)}")]


# Tool 3 Mode Handlers
async def _extract_direct(args: dict[str, Any]) -> dict[str, Any]:
    """Mode: direct - Extract direct mechanistic edges between specified genes."""
    genes = args["genes"]
    resolver = get_resolver()
    resolved_genes = []
    for gene in genes:
        resolved = await resolver.resolve_gene(gene)
        resolved_genes.append(resolved)

    adapter = await get_adapter()
    query_params = {
        "gene_ids": [g.curie for g in resolved_genes],
        "statement_types": args.get("statement_types"),
        "min_evidence": args.get("min_evidence_count", 1),
        "min_belief": args.get("min_belief_score", 0.0),
        "max_statements": args.get("max_statements", 100),
        "timeout": STANDARD_QUERY_TIMEOUT,
    }
    if args.get("tissue_filter"):
        query_params["tissue"] = args["tissue_filter"]
    if args.get("go_filter"):
        query_params["go_term"] = args["go_filter"]

    stmt_data = await adapter.query("indra_subnetwork", **query_params)
    statements = _parse_subnetwork_statements(stmt_data, args.get("include_evidence", False))
    nodes = _extract_nodes_from_statements(statements, resolved_genes)
    statistics = _compute_network_statistics(nodes, statements)

    return {"nodes": nodes, "statements": statements, "statistics": statistics}


async def _extract_mediated(args: dict[str, Any]) -> dict[str, Any]:
    """Mode: mediated - Find two-hop paths connecting genes through intermediates."""
    genes = args["genes"]
    resolver = get_resolver()
    resolved_genes = []
    for gene in genes:
        resolved = await resolver.resolve_gene(gene)
        resolved_genes.append(resolved)

    adapter = await get_adapter()
    query_params = {
        "gene_ids": [g.curie for g in resolved_genes],
        "statement_types": args.get("statement_types"),
        "min_evidence": args.get("min_evidence_count", 1),
        "min_belief": args.get("min_belief_score", 0.0),
        "max_statements": args.get("max_statements", 100),
        "timeout": STANDARD_QUERY_TIMEOUT,
    }
    if args.get("tissue_filter"):
        query_params["tissue"] = args["tissue_filter"]
    if args.get("go_filter"):
        query_params["go_term"] = args["go_filter"]

    stmt_data = await adapter.query("indra_mediated_subnetwork", **query_params)
    statements = _parse_subnetwork_statements(stmt_data, args.get("include_evidence", False))
    nodes = _extract_nodes_from_statements(statements, resolved_genes)
    statistics = _compute_network_statistics(nodes, statements)

    return {"nodes": nodes, "statements": statements, "statistics": statistics, "note": "Paths shown are two-hop"}


async def _extract_shared_upstream(args: dict[str, Any]) -> dict[str, Any]:
    """Mode: shared_upstream - Find shared regulators."""
    genes = args["genes"]
    resolver = get_resolver()
    resolved_genes = []
    for gene in genes:
        resolved = await resolver.resolve_gene(gene)
        resolved_genes.append(resolved)

    return {
        "nodes": [{"name": g.name, "curie": g.curie, "namespace": g.namespace, "identifier": g.identifier} for g in resolved_genes],
        "statements": [],
        "statistics": {"node_count": len(resolved_genes), "edge_count": 0, "statement_types": {}, "avg_evidence_per_statement": 0.0, "avg_belief_score": 0.0},
        "note": "Shared upstream queries not yet implemented in backend",
    }


async def _extract_shared_downstream(args: dict[str, Any]) -> dict[str, Any]:
    """Mode: shared_downstream - Find shared targets."""
    genes = args["genes"]
    resolver = get_resolver()
    resolved_genes = []
    for gene in genes:
        resolved = await resolver.resolve_gene(gene)
        resolved_genes.append(resolved)

    return {
        "nodes": [{"name": g.name, "curie": g.curie, "namespace": g.namespace, "identifier": g.identifier} for g in resolved_genes],
        "statements": [],
        "statistics": {"node_count": len(resolved_genes), "edge_count": 0, "statement_types": {}, "avg_evidence_per_statement": 0.0, "avg_belief_score": 0.0},
        "note": "Shared downstream queries not yet implemented in backend",
    }


async def _extract_source_to_targets(args: dict[str, Any]) -> dict[str, Any]:
    """Mode: source_to_targets - Find all downstream targets of a source gene."""
    source_gene = args["source_gene"]
    resolver = get_resolver()
    source = await resolver.resolve_gene(source_gene)

    target_genes = []
    if args.get("target_genes"):
        for gene in args["target_genes"]:
            resolved = await resolver.resolve_gene(gene)
            target_genes.append(resolved)

    adapter = await get_adapter()
    query_params = {
        "source_gene_id": source.curie,
        "statement_types": args.get("statement_types"),
        "min_evidence": args.get("min_evidence_count", 1),
        "min_belief": args.get("min_belief_score", 0.0),
        "max_statements": args.get("max_statements", 100),
        "timeout": STANDARD_QUERY_TIMEOUT,
    }
    if target_genes:
        query_params["target_gene_ids"] = [g.curie for g in target_genes]
    if args.get("tissue_filter"):
        query_params["tissue"] = args["tissue_filter"]
    if args.get("go_filter"):
        query_params["go_term"] = args["go_filter"]

    stmt_data = await adapter.query("source_target_analysis", **query_params)
    statements = _parse_subnetwork_statements(stmt_data, args.get("include_evidence", False))
    all_resolved = [source] + target_genes
    nodes = _extract_nodes_from_statements(statements, all_resolved)
    statistics = _compute_network_statistics(nodes, statements)

    return {
        "source_gene": {"name": source.name, "curie": source.curie, "namespace": source.namespace, "identifier": source.identifier},
        "nodes": nodes,
        "statements": statements,
        "statistics": statistics,
    }


def _parse_subnetwork_statements(data: dict[str, Any], include_evidence: bool = False) -> list[dict[str, Any]]:
    """Parse INDRA statements from backend response."""
    if not data.get("success") or not data.get("statements"):
        return []

    statements = []
    for record in data["statements"]:
        stmt = {
            "stmt_hash": record.get("hash", ""),
            "stmt_type": record.get("type", "Unknown"),
            "subject": {
                "name": record.get("subj_name", "Unknown"),
                "curie": record.get("subj_id", "unknown:unknown"),
                "namespace": record.get("subj_namespace", "unknown"),
                "identifier": record.get("subj_identifier", "unknown"),
            },
            "object": {
                "name": record.get("obj_name", "Unknown"),
                "curie": record.get("obj_id", "unknown:unknown"),
                "namespace": record.get("obj_namespace", "unknown"),
                "identifier": record.get("obj_identifier", "unknown"),
            },
            "residue": record.get("residue"),
            "position": record.get("position"),
            "evidence_count": record.get("evidence_count", 0),
            "belief_score": record.get("belief", 0.0),
            "sources": record.get("sources", []),
        }
        if include_evidence:
            stmt["evidence"] = record.get("evidence")
        statements.append(stmt)

    return statements


def _extract_nodes_from_statements(statements: list[dict[str, Any]], resolved_genes: list) -> list[dict[str, Any]]:
    """Extract unique nodes from statements and resolved genes."""
    nodes_dict: dict[str, dict[str, Any]] = {}
    for gene in resolved_genes:
        nodes_dict[gene.curie] = {"name": gene.name, "curie": gene.curie, "namespace": gene.namespace, "identifier": gene.identifier}

    for stmt in statements:
        if stmt["subject"]["curie"] not in nodes_dict:
            nodes_dict[stmt["subject"]["curie"]] = stmt["subject"]
        if stmt["object"]["curie"] not in nodes_dict:
            nodes_dict[stmt["object"]["curie"]] = stmt["object"]

    return list(nodes_dict.values())


def _compute_network_statistics(nodes: list[dict[str, Any]], statements: list[dict[str, Any]]) -> dict[str, Any]:
    """Compute network-level statistics."""
    stmt_types: dict[str, int] = {}
    total_evidence = 0
    total_belief = 0.0

    for stmt in statements:
        stmt_type = stmt["stmt_type"]
        stmt_types[stmt_type] = stmt_types.get(stmt_type, 0) + 1
        total_evidence += stmt["evidence_count"]
        total_belief += stmt["belief_score"]

    return {
        "node_count": len(nodes),
        "edge_count": len(statements),
        "statement_types": stmt_types,
        "avg_evidence_per_statement": total_evidence / len(statements) if statements else 0.0,
        "avg_belief_score": total_belief / len(statements) if statements else 0.0,
    }


async def _handle_enrichment_analysis(args: dict[str, Any]) -> list[types.TextContent]:
    """Handle enrichment analysis - Tool 4."""
    try:
        analysis_type = args.get("analysis_type")
        response_format = args.get("response_format", "markdown")

        # Route to appropriate handler based on analysis type
        if analysis_type == "discrete":
            result = await _analyze_discrete(args)
        elif analysis_type == "continuous":
            result = await _analyze_continuous(args)
        elif analysis_type == "signed":
            result = await _analyze_signed(args)
        elif analysis_type == "metabolite":
            result = await _analyze_metabolite(args)
        else:
            return [types.TextContent(
                type="text",
                text=f"Error: Unknown analysis type '{analysis_type}'"
            )]

        # Format response
        formatter = get_formatter()
        response = formatter.format_response(
            data=result,
            format_type=response_format,
            max_chars=CHARACTER_LIMIT,
        )

        return [types.TextContent(type="text", text=response)]

    except EntityResolutionError as e:
        logger.warning(f"Entity resolution error: {e}")
        return [types.TextContent(type="text", text=f"Error: {str(e)}")]
    except ValueError as e:
        logger.warning(f"Validation error: {e}")
        return [types.TextContent(type="text", text=f"Error: {str(e)}")]
    except Exception as e:
        logger.error(f"Tool error: {e}", exc_info=True)
        return [types.TextContent(type="text", text=f"Error: Unexpected error occurred. {str(e)}")]


# Tool 4 Mode Handlers
async def _analyze_discrete(args: dict[str, Any]) -> dict[str, Any]:
    """Mode: discrete - Overrepresentation analysis using Fisher's exact test."""
    if not args.get("gene_list"):
        raise ValueError("gene_list parameter required for discrete analysis")

    # Resolve gene identifiers
    resolver = get_resolver()
    resolved_genes = []
    failed_genes = []

    for gene in args["gene_list"]:
        try:
            resolved = await resolver.resolve_gene(gene)
            resolved_genes.append(resolved)
        except EntityResolutionError as e:
            logger.warning(f"Failed to resolve gene '{gene}': {e}")
            failed_genes.append(gene)

    if not resolved_genes:
        raise ValueError(f"No genes could be resolved. Failed: {', '.join(failed_genes)}")

    if failed_genes:
        logger.info(
            f"Proceeding with {len(resolved_genes)}/{len(args['gene_list'])} genes. "
            f"Failed: {', '.join(failed_genes[:5])}{'...' if len(failed_genes) > 5 else ''}"
        )

    # Optionally resolve background genes
    background_gene_ids = None
    if args.get("background_genes"):
        background_resolved = []
        for gene in args["background_genes"]:
            try:
                resolved = await resolver.resolve_gene(gene)
                background_resolved.append(resolved)
            except EntityResolutionError:
                pass
        background_gene_ids = [g.curie for g in background_resolved]

    # Query backend
    adapter = await get_adapter()

    query_params = {
        "gene_ids": [g.curie for g in resolved_genes],
        "source": args.get("source", "go"),
        "alpha": args.get("alpha", 0.05),
        "correction_method": args.get("correction_method", "fdr_bh"),
        "keep_insignificant": args.get("keep_insignificant", False),
        "timeout": ENRICHMENT_TIMEOUT,
    }

    if background_gene_ids:
        query_params["background_gene_ids"] = background_gene_ids

    # Add INDRA-specific parameters if applicable
    source = args.get("source", "go")
    if source in ["indra-upstream", "indra-downstream"]:
        query_params["min_evidence_count"] = args.get("min_evidence_count", 1)
        query_params["min_belief_score"] = args.get("min_belief_score", 0.0)

    enrichment_data = await adapter.query("discrete_analysis", **query_params)

    # Parse results
    results = _parse_enrichment_results(enrichment_data, analysis_type="discrete")
    statistics = _compute_enrichment_statistics(results, args, len(resolved_genes))

    return {
        "results": [r for r in results],
        "statistics": statistics,
        "resolved_genes": len(resolved_genes),
        "failed_genes": failed_genes if failed_genes else None,
    }


async def _analyze_continuous(args: dict[str, Any]) -> dict[str, Any]:
    """Mode: continuous - Gene Set Enrichment Analysis (GSEA) with ranked gene list."""
    if not args.get("ranked_genes"):
        raise ValueError("ranked_genes parameter required for continuous analysis")

    # Resolve gene identifiers and preserve scores
    resolver = get_resolver()
    resolved_ranking: dict[str, float] = {}
    failed_genes = []

    for gene, score in args["ranked_genes"].items():
        try:
            resolved = await resolver.resolve_gene(gene)
            resolved_ranking[resolved.curie] = score
        except EntityResolutionError as e:
            logger.warning(f"Failed to resolve gene '{gene}': {e}")
            failed_genes.append(gene)

    if not resolved_ranking:
        raise ValueError(f"No genes could be resolved. Failed: {', '.join(failed_genes)}")

    # Query backend
    adapter = await get_adapter()

    query_params = {
        "ranked_genes": resolved_ranking,
        "source": args.get("source", "go"),
        "alpha": args.get("alpha", 0.05),
        "correction_method": args.get("correction_method", "fdr_bh"),
        "permutations": args.get("permutations", 1000),
        "keep_insignificant": args.get("keep_insignificant", False),
        "timeout": ENRICHMENT_TIMEOUT,
    }

    # Add INDRA-specific parameters if applicable
    source = args.get("source", "go")
    if source in ["indra-upstream", "indra-downstream"]:
        query_params["min_evidence_count"] = args.get("min_evidence_count", 1)
        query_params["min_belief_score"] = args.get("min_belief_score", 0.0)

    enrichment_data = await adapter.query("continuous_analysis", **query_params)

    # Parse results
    results = _parse_enrichment_results(enrichment_data, analysis_type="continuous")
    statistics = _compute_enrichment_statistics(results, args, len(resolved_ranking))

    return {
        "results": [r for r in results],
        "statistics": statistics,
        "resolved_genes": len(resolved_ranking),
        "failed_genes": failed_genes if failed_genes else None,
    }


async def _analyze_signed(args: dict[str, Any]) -> dict[str, Any]:
    """Mode: signed - Directional enrichment analysis (separate up/down regulation)."""
    if not args.get("ranked_genes"):
        raise ValueError("ranked_genes parameter required for signed analysis")

    # Resolve gene identifiers and preserve signed scores
    resolver = get_resolver()
    resolved_ranking: dict[str, float] = {}
    failed_genes = []

    for gene, score in args["ranked_genes"].items():
        try:
            resolved = await resolver.resolve_gene(gene)
            resolved_ranking[resolved.curie] = score
        except EntityResolutionError as e:
            logger.warning(f"Failed to resolve gene '{gene}': {e}")
            failed_genes.append(gene)

    if not resolved_ranking:
        raise ValueError(f"No genes could be resolved. Failed: {', '.join(failed_genes)}")

    # Count up/down regulated genes
    upregulated = sum(1 for score in resolved_ranking.values() if score > 0)
    downregulated = sum(1 for score in resolved_ranking.values() if score < 0)

    # Query backend
    adapter = await get_adapter()

    query_params = {
        "ranked_genes": resolved_ranking,
        "source": args.get("source", "go"),
        "alpha": args.get("alpha", 0.05),
        "correction_method": args.get("correction_method", "fdr_bh"),
        "permutations": args.get("permutations", 1000),
        "keep_insignificant": args.get("keep_insignificant", False),
        "timeout": ENRICHMENT_TIMEOUT,
    }

    # Add INDRA-specific parameters if applicable
    source = args.get("source", "go")
    if source in ["indra-upstream", "indra-downstream"]:
        query_params["min_evidence_count"] = args.get("min_evidence_count", 1)
        query_params["min_belief_score"] = args.get("min_belief_score", 0.0)

    enrichment_data = await adapter.query("signed_analysis", **query_params)

    # Parse results
    results = _parse_enrichment_results(enrichment_data, analysis_type="signed")
    statistics = _compute_enrichment_statistics(results, args, len(resolved_ranking))

    return {
        "results": [r for r in results],
        "statistics": statistics,
        "resolved_genes": len(resolved_ranking),
        "upregulated_count": upregulated,
        "downregulated_count": downregulated,
        "failed_genes": failed_genes if failed_genes else None,
    }


async def _analyze_metabolite(args: dict[str, Any]) -> dict[str, Any]:
    """Mode: metabolite - Metabolite set enrichment analysis."""
    if not args.get("gene_list"):
        raise ValueError("gene_list parameter required for metabolite analysis")

    # For metabolite analysis, we don't resolve through gene resolver
    # Metabolites have their own identifier format (e.g., HMDB, ChEBI)
    # Pass them directly to backend
    metabolite_ids = args["gene_list"]

    # Optionally resolve background metabolites
    background_metabolite_ids = args.get("background_genes") if args.get("background_genes") else None

    # Query backend
    adapter = await get_adapter()

    query_params = {
        "metabolite_ids": metabolite_ids,
        "source": args.get("source", "go"),
        "alpha": args.get("alpha", 0.05),
        "correction_method": args.get("correction_method", "fdr_bh"),
        "keep_insignificant": args.get("keep_insignificant", False),
        "timeout": ENRICHMENT_TIMEOUT,
    }

    if background_metabolite_ids:
        query_params["background_metabolite_ids"] = background_metabolite_ids

    enrichment_data = await adapter.query("metabolite_discrete_analysis", **query_params)

    # Parse results
    results = _parse_enrichment_results(enrichment_data, analysis_type="metabolite")
    statistics = _compute_enrichment_statistics(results, args, len(metabolite_ids))

    return {
        "results": [r for r in results],
        "statistics": statistics,
        "total_metabolites": len(metabolite_ids),
    }


# Data parsing helpers for Tool 4
def _parse_enrichment_results(data: dict[str, Any], analysis_type: str) -> list[dict[str, Any]]:
    """Parse enrichment results from backend response."""
    if not data.get("success") or not data.get("results"):
        return []

    results = []
    for record in data["results"]:
        # Parse term entity
        term = {
            "name": record.get("term_name", "Unknown"),
            "curie": record.get("term_id", "unknown:unknown"),
            "namespace": record.get("term_namespace", "unknown"),
            "identifier": record.get("term_identifier", "unknown"),
        }

        # Build result object
        result_dict = {
            "term": term,
            "term_name": record.get("term_name", "Unknown"),
            "p_value": record.get("p_value", 1.0),
            "adjusted_p_value": record.get("adjusted_p_value", 1.0),
            "gene_count": record.get("gene_count", 0),
            "term_size": record.get("term_size", 0),
            "genes": record.get("genes", []),
            "background_count": record.get("background_count"),
        }

        # Add GSEA-specific fields for continuous/signed analysis
        if analysis_type in ["continuous", "signed"]:
            result_dict["enrichment_score"] = record.get("enrichment_score")
            result_dict["normalized_enrichment_score"] = record.get("normalized_enrichment_score")

        results.append(result_dict)

    return results


def _compute_enrichment_statistics(results: list[dict[str, Any]], args: dict[str, Any], total_genes: int) -> dict[str, Any]:
    """Compute overall enrichment statistics."""
    # Count significant results
    alpha = args.get("alpha", 0.05)
    significant_results = sum(1 for r in results if r.get("adjusted_p_value", 1.0) <= alpha)

    return {
        "total_results": len(results),
        "significant_results": significant_results,
        "total_genes_analyzed": total_genes,
        "correction_method": args.get("correction_method", "fdr_bh"),
        "alpha": alpha,
    }


def _parse_disease_associations(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse disease associations from backend response."""
    if not data.get("success") or not data.get("records"):
        return []

    diseases = []
    for record in data["records"]:
        diseases.append({
            "disease": {
                "name": record.get("disease", "Unknown"),
                "curie": record.get("disease_id", "unknown:unknown"),
            },
            "score": record.get("score", 0.0),
            "evidence_count": record.get("evidence_count", 0),
        })

    return diseases


async def _handle_drug_effect_query(args: dict[str, Any]) -> list[types.TextContent]:
    """Handle drug/effect query - Tool 5."""
    try:
        mode = args.get("mode")
        response_format = args.get("response_format", "markdown")

        # Route to appropriate handler based on mode
        if mode == "drug_to_profile":
            if not args.get("drug"):
                return [types.TextContent(
                    type="text",
                    text="Error: drug parameter required for drug_to_profile mode"
                )]
            result = await _drug_to_profile(args)
        elif mode == "side_effect_to_drugs":
            if not args.get("side_effect"):
                return [types.TextContent(
                    type="text",
                    text="Error: side_effect parameter required for side_effect_to_drugs mode"
                )]
            result = await _side_effect_to_drugs(args)
        else:
            return [types.TextContent(
                type="text",
                text=f"Error: Unknown query mode '{mode}'"
            )]

        # Format response
        formatter = get_formatter()
        response = formatter.format_response(
            data=result,
            format_type=response_format,
            max_chars=CHARACTER_LIMIT,
        )

        return [types.TextContent(type="text", text=response)]

    except EntityResolutionError as e:
        logger.warning(f"Entity resolution error: {e}")
        return [types.TextContent(type="text", text=f"Error: {str(e)}")]
    except Exception as e:
        logger.error(f"Tool error: {e}", exc_info=True)
        return [types.TextContent(type="text", text=f"Error: Unexpected error occurred. {str(e)}")]


# Tool 5 Mode Handlers
async def _drug_to_profile(args: dict[str, Any]) -> dict[str, Any]:
    """Mode: drug_to_profile - Get comprehensive drug profile with all requested features."""
    drug_input = args["drug"]

    # Resolve drug identifier
    resolver = get_resolver()
    drug = await resolver.resolve_drug(drug_input)

    adapter = await get_adapter()
    result = {
        "drug": {
            "name": drug.name,
            "curie": drug.curie,
            "namespace": drug.namespace,
            "identifier": drug.identifier,
        }
    }

    # Fetch requested features
    if args.get("include_targets", True):
        target_data = await adapter.query(
            "get_targets_for_drug",
            drug_id=drug.curie,
            timeout=STANDARD_QUERY_TIMEOUT,
        )
        result["targets"] = _parse_drug_targets(target_data)

    if args.get("include_indications", True):
        indication_data = await adapter.query(
            "get_indications_for_drug",
            drug_id=drug.curie,
            timeout=STANDARD_QUERY_TIMEOUT,
        )
        result["indications"] = _parse_drug_indications(indication_data)

    if args.get("include_side_effects", True):
        side_effect_data = await adapter.query(
            "get_side_effects_for_drug",
            drug_id=drug.curie,
            timeout=STANDARD_QUERY_TIMEOUT,
        )
        result["side_effects"] = _parse_drug_side_effects(side_effect_data)

    if args.get("include_trials", False):
        trial_data = await adapter.query(
            "get_trials_for_drug",
            drug_id=drug.curie,
            timeout=STANDARD_QUERY_TIMEOUT,
        )
        result["trials"] = _parse_drug_trials(trial_data)

    if args.get("include_cell_lines", False):
        cell_line_data = await adapter.query(
            "get_sensitive_cell_lines_for_drug",
            drug_id=drug.curie,
            timeout=STANDARD_QUERY_TIMEOUT,
        )
        result["cell_lines"] = _parse_drug_cell_lines(cell_line_data)

    return result


async def _side_effect_to_drugs(args: dict[str, Any]) -> dict[str, Any]:
    """Mode: side_effect_to_drugs - Find drugs associated with a specific side effect."""
    side_effect_input = args["side_effect"]
    limit = args.get("limit", 20)
    offset = args.get("offset", 0)

    # Parse side effect identifier
    # For now, accept side effect name directly
    side_effect_id = side_effect_input if isinstance(side_effect_input, str) else side_effect_input[1]

    adapter = await get_adapter()
    drug_data = await adapter.query(
        "get_drugs_for_side_effect",
        side_effect_id=side_effect_id,
        limit=limit,
        offset=offset,
        timeout=STANDARD_QUERY_TIMEOUT,
    )

    # Parse drugs
    drugs = _parse_drug_list_for_side_effect(drug_data)

    # Create pagination metadata
    pagination_service = get_pagination()
    pagination = pagination_service.paginate(
        items=drugs,
        total_count=drug_data.get("total_count", len(drugs)),
        offset=offset,
        limit=limit,
    )

    return {
        "drugs": drugs,
        "pagination": pagination.model_dump(),
    }


# Data parsing helpers for Tool 5
def _parse_drug_targets(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse drug targets from backend response."""
    if not data.get("success") or not data.get("records"):
        return []

    targets = []
    for record in data["records"]:
        targets.append({
            "target": {
                "name": record.get("target", "Unknown"),
                "curie": record.get("target_id", "unknown:unknown"),
                "namespace": record.get("target_namespace", "hgnc"),
                "identifier": record.get("target_id", "unknown"),
            },
            "action_type": record.get("action_type"),
            "evidence_count": record.get("evidence_count", 0),
        })

    return targets


def _parse_drug_indications(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse drug indications from backend response."""
    if not data.get("success") or not data.get("records"):
        return []

    indications = []
    for record in data["records"]:
        indications.append({
            "disease": {
                "name": record.get("disease", "Unknown"),
                "curie": record.get("disease_id", "unknown:unknown"),
                "namespace": "mondo",
                "identifier": record.get("disease_id", "unknown"),
            },
            "indication_type": record.get("indication_type", "unknown"),
            "max_phase": record.get("max_phase"),
        })

    return indications


def _parse_drug_side_effects(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse side effects from backend response."""
    if not data.get("success") or not data.get("records"):
        return []

    side_effects = []
    for record in data["records"]:
        side_effects.append({
            "effect": {
                "name": record.get("effect", "Unknown"),
                "curie": record.get("effect_id", "unknown:unknown"),
                "namespace": "umls",
                "identifier": record.get("effect_id", "unknown"),
            },
            "frequency": record.get("frequency"),
        })

    return side_effects


def _parse_drug_trials(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse clinical trials from backend response."""
    if not data.get("success") or not data.get("records"):
        return []

    trials = []
    for record in data["records"]:
        nct_id = record.get("nct_id", "unknown")
        trials.append({
            "nct_id": nct_id,
            "title": record.get("title", "Unknown"),
            "phase": record.get("phase"),
            "status": record.get("status", "unknown"),
            "conditions": record.get("conditions", []),
            "interventions": record.get("interventions", []),
            "url": f"https://clinicaltrials.gov/ct2/show/{nct_id}",
        })

    return trials


def _parse_drug_cell_lines(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse cell line sensitivity data from backend response."""
    if not data.get("success") or not data.get("records"):
        return []

    cell_lines = []
    for record in data["records"]:
        cell_lines.append({
            "cell_line": record.get("cell_line", "Unknown"),
            "sensitivity_score": record.get("sensitivity_score", 0.0),
        })

    return cell_lines


def _parse_drug_list_for_side_effect(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse drug list from backend response."""
    if not data.get("success") or not data.get("records"):
        return []

    drugs = []
    for record in data["records"]:
        drugs.append({
            "name": record.get("drug", "Unknown"),
            "curie": record.get("drug_id", "unknown:unknown"),
            "namespace": "chembl",
            "identifier": record.get("drug_id", "unknown"),
            "synonyms": record.get("synonyms", []),
            "drug_type": record.get("drug_type"),
        })

    return drugs


async def _handle_pathway_query(args: dict[str, Any]) -> list[types.TextContent]:
    """Handle pathway query - Tool 6."""
    return [types.TextContent(type="text", text="Tool 6 implementation: Pathway queries")]


async def _handle_cell_line_query(args: dict[str, Any]) -> list[types.TextContent]:
    """Handle cell line query - Tool 7."""
    return [types.TextContent(type="text", text="Tool 7 implementation: Cell line queries")]


async def _handle_clinical_trials_query(args: dict[str, Any]) -> list[types.TextContent]:
    """Handle clinical trials query - Tool 8."""
    return [types.TextContent(type="text", text="Tool 8 implementation: Clinical trials queries")]



# ============================================================================
# Tool 9: Literature Query
# ============================================================================

async def _handle_literature_query(args: dict[str, Any]) -> list[types.TextContent]:
    """Handle literature query - Tool 9."""
    try:
        mode = args.get("mode")
        response_format = args.get("response_format", "markdown")

        # Route to appropriate handler based on mode
        if mode == "get_statements_for_pmid":
            if not args.get("pmid"):
                return [types.TextContent(
                    type="text",
                    text="Error: pmid parameter required for get_statements_for_pmid mode"
                )]
            result = await _get_statements_for_pmid(args)
        elif mode == "get_evidence_for_statement":
            if not args.get("statement_hash"):
                return [types.TextContent(
                    type="text",
                    text="Error: statement_hash parameter required for get_evidence_for_statement mode"
                )]
            result = await _get_evidence_for_statement(args)
        elif mode == "search_by_mesh":
            if not args.get("mesh_terms") or len(args.get("mesh_terms", [])) == 0:
                return [types.TextContent(
                    type="text",
                    text="Error: mesh_terms parameter required for search_by_mesh mode"
                )]
            result = await _search_by_mesh(args)
        elif mode == "get_statements_by_hashes":
            if not args.get("statement_hashes") or len(args.get("statement_hashes", [])) == 0:
                return [types.TextContent(
                    type="text",
                    text="Error: statement_hashes parameter required for get_statements_by_hashes mode"
                )]
            result = await _get_statements_by_hashes(args)
        else:
            return [types.TextContent(
                type="text",
                text=f"Error: Unknown literature query mode '{mode}'"
            )]

        # Format response
        formatter = get_formatter()
        response = formatter.format_response(
            data=result,
            format_type=response_format,
            max_chars=CHARACTER_LIMIT,
        )

        return [types.TextContent(type="text", text=response)]

    except Exception as e:
        logger.error(f"Tool error: {e}", exc_info=True)
        return [types.TextContent(type="text", text=f"Error: Unexpected error occurred. {str(e)}")]


# Tool 9 Mode Handlers
async def _get_statements_for_pmid(args: dict[str, Any]) -> dict[str, Any]:
    """Mode: get_statements_for_pmid - Retrieve INDRA statements from a specific PubMed publication."""
    pmid = args["pmid"]
    limit = args.get("limit", 20)
    offset = args.get("offset", 0)
    include_evidence_text = args.get("include_evidence_text", True)
    max_evidence_per_statement = args.get("max_evidence_per_statement", 5)

    adapter = await get_adapter()
    query_params = {
        "pmid": pmid,
        "limit": limit,
        "offset": offset,
        "include_evidence": include_evidence_text,
        "max_evidence": max_evidence_per_statement,
        "timeout": STANDARD_QUERY_TIMEOUT,
    }

    stmt_data = await adapter.query("get_statements_for_paper", **query_params)

    # Parse statements
    statements = _parse_literature_statements(stmt_data, include_evidence_text)

    # Build pagination
    total_count = stmt_data.get("total_count", len(statements))
    pagination = _build_literature_pagination(
        total_count=total_count,
        count=len(statements),
        offset=offset,
        limit=limit,
    )

    return {
        "pmid": pmid,
        "statements": statements,
        "pagination": pagination,
    }


async def _get_evidence_for_statement(args: dict[str, Any]) -> dict[str, Any]:
    """Mode: get_evidence_for_statement - Retrieve evidence text snippets for a specific INDRA statement."""
    statement_hash = args["statement_hash"]
    limit = args.get("limit", 20)
    offset = args.get("offset", 0)
    max_evidence_per_statement = args.get("max_evidence_per_statement", 5)

    adapter = await get_adapter()
    query_params = {
        "stmt_hash": statement_hash,
        "limit": limit,
        "offset": offset,
        "max_evidence": max_evidence_per_statement,
        "timeout": STANDARD_QUERY_TIMEOUT,
    }

    evidence_data = await adapter.query("get_evidences_for_stmt_hash", **query_params)

    # Parse evidence
    evidence_list = _parse_literature_evidence(evidence_data)

    # Build pagination
    total_count = evidence_data.get("total_count", len(evidence_list))
    pagination = _build_literature_pagination(
        total_count=total_count,
        count=len(evidence_list),
        offset=offset,
        limit=limit,
    )

    return {
        "statement_hash": statement_hash,
        "evidence": evidence_list,
        "pagination": pagination,
    }


async def _search_by_mesh(args: dict[str, Any]) -> dict[str, Any]:
    """Mode: search_by_mesh - Search PubMed publications by MeSH terms."""
    mesh_terms = args["mesh_terms"]
    limit = args.get("limit", 20)
    offset = args.get("offset", 0)

    adapter = await get_adapter()
    query_params = {
        "mesh_terms": mesh_terms,
        "limit": limit,
        "offset": offset,
        "timeout": STANDARD_QUERY_TIMEOUT,
    }

    pub_data = await adapter.query("get_evidence_for_mesh", **query_params)

    # Parse publications
    publications = _parse_literature_publications(pub_data)

    # Build pagination
    total_count = pub_data.get("total_count", len(publications))
    pagination = _build_literature_pagination(
        total_count=total_count,
        count=len(publications),
        offset=offset,
        limit=limit,
    )

    return {
        "mesh_terms": mesh_terms,
        "publications": publications,
        "pagination": pagination,
    }


async def _get_statements_by_hashes(args: dict[str, Any]) -> dict[str, Any]:
    """Mode: get_statements_by_hashes - Batch retrieve INDRA statements by their hashes."""
    statement_hashes = args["statement_hashes"]
    include_evidence_text = args.get("include_evidence_text", True)
    max_evidence_per_statement = args.get("max_evidence_per_statement", 5)

    adapter = await get_adapter()
    query_params = {
        "stmt_hashes": statement_hashes,
        "include_evidence": include_evidence_text,
        "max_evidence": max_evidence_per_statement,
        "timeout": STANDARD_QUERY_TIMEOUT,
    }

    stmt_data = await adapter.query("get_stmts_for_stmt_hashes", **query_params)

    # Parse statements
    statements = _parse_literature_statements(stmt_data, include_evidence_text)

    # Build pagination (batch retrieval doesn't use offset/limit)
    pagination = _build_literature_pagination(
        total_count=len(statements),
        count=len(statements),
        offset=0,
        limit=len(statements),
    )

    return {
        "statements": statements,
        "pagination": pagination,
    }


# Data parsing helpers for Tool 9
def _parse_literature_statements(data: dict[str, Any], include_evidence: bool = False) -> list[dict[str, Any]]:
    """Parse INDRA statements from backend response."""
    if not data.get("success") or not data.get("statements"):
        return []

    statements = []
    for record in data["statements"]:
        # Parse evidence if requested
        evidence = None
        if include_evidence and record.get("evidence"):
            evidence = record["evidence"]

        stmt = {
            "stmt_hash": record.get("hash", ""),
            "stmt_type": record.get("type", "Unknown"),
            "subject": {
                "name": record.get("subj_name", "Unknown"),
                "curie": record.get("subj_id", "unknown:unknown"),
                "namespace": record.get("subj_namespace", "unknown"),
                "identifier": record.get("subj_identifier", "unknown"),
            },
            "object": {
                "name": record.get("obj_name", "Unknown"),
                "curie": record.get("obj_id", "unknown:unknown"),
                "namespace": record.get("obj_namespace", "unknown"),
                "identifier": record.get("obj_identifier", "unknown"),
            },
            "residue": record.get("residue"),
            "position": record.get("position"),
            "evidence_count": record.get("evidence_count", 0),
            "belief_score": record.get("belief", 0.0),
            "sources": record.get("sources", []),
            "evidence": evidence,
        }
        statements.append(stmt)

    return statements


def _parse_literature_evidence(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse evidence snippets from backend response."""
    if not data.get("success") or not data.get("evidence"):
        return []

    evidence_list = []
    for record in data["evidence"]:
        evidence = {
            "text": record.get("text", ""),
            "pmid": record.get("pmid"),
            "source_api": record.get("source_api", "unknown"),
            "annotations": record.get("annotations"),
        }
        evidence_list.append(evidence)

    return evidence_list


def _parse_literature_publications(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse PubMed publications from backend response."""
    if not data.get("success") or not data.get("publications"):
        return []

    publications = []
    for record in data["publications"]:
        pmid = record.get("pmid", "")
        pub = {
            "pmid": pmid,
            "title": record.get("title", ""),
            "authors": record.get("authors", []),
            "journal": record.get("journal", ""),
            "year": record.get("year", 0),
            "abstract": record.get("abstract"),
            "mesh_terms": record.get("mesh_terms", []),
            "url": f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/",
        }
        publications.append(pub)

    return publications


def _build_literature_pagination(total_count: int, count: int, offset: int, limit: int) -> dict[str, Any]:
    """Build pagination metadata."""
    has_more = (offset + count) < total_count
    next_offset = offset + count if has_more else None

    return {
        "total_count": total_count,
        "count": count,
        "offset": offset,
        "limit": limit,
        "has_more": has_more,
        "next_offset": next_offset,
    }

async def _handle_variants_query(args: dict[str, Any]) -> list[types.TextContent]:
    """Handle variants query - Tool 10."""
    return [types.TextContent(type="text", text="Tool 10 implementation: Variants queries")]


async def _handle_identifier_resolution(args: dict[str, Any]) -> list[types.TextContent]:
    """Handle identifier resolution - Tool 11."""
    return [types.TextContent(type="text", text="Tool 11 implementation: Identifier resolution")]


async def _handle_relationship_check(args: dict[str, Any]) -> list[types.TextContent]:
    """Handle relationship check - Tool 12."""
    return [types.TextContent(type="text", text="Tool 12 implementation: Relationship checks")]


async def _handle_ontology_hierarchy(args: dict[str, Any]) -> list[types.TextContent]:
    """Handle ontology hierarchy - Tool 13."""
    return [types.TextContent(type="text", text="Tool 13 implementation: Ontology hierarchy")]


async def _handle_cell_markers_query(args: dict[str, Any]) -> list[types.TextContent]:
    """Handle cell markers query - Tool 14."""
    return [types.TextContent(type="text", text="Tool 14 implementation: Cell markers queries")]


async def _handle_kinase_enrichment(args: dict[str, Any]) -> list[types.TextContent]:
    """Handle kinase enrichment - Tool 15."""
    try:
        # Validate phosphosites
        phosphosites = args.get("phosphosites", [])
        if not phosphosites:
            return [types.TextContent(
                type="text",
                text="Error: phosphosites parameter is required and cannot be empty"
            )]

        # Validate phosphosite format
        pattern = re.compile(r"^[A-Z0-9]+_[STY]\d+$", re.IGNORECASE)
        invalid_sites = [site for site in phosphosites if not pattern.match(site)]
        if invalid_sites:
            return [types.TextContent(
                type="text",
                text=f"Error: Invalid phosphosite format: {', '.join(invalid_sites[:5])}. "
                     f"Expected format: GENE_S123 (serine), GENE_T456 (threonine), or GENE_Y789 (tyrosine)"
            )]

        # Count unique genes in phosphosites
        unique_genes = set(site.split("_")[0] for site in phosphosites)

        # Prepare background phosphosites if provided
        background_sites = args.get("background")
        if background_sites:
            invalid_bg = [site for site in background_sites if not pattern.match(site)]
            if invalid_bg:
                return [types.TextContent(
                    type="text",
                    text=f"Error: Invalid background phosphosite format: {', '.join(invalid_bg[:5])}"
                )]

        # Query backend
        adapter = await get_adapter()

        query_params = {
            "phosphosites": phosphosites,
            "alpha": args.get("alpha", 0.05),
            "correction_method": args.get("correction_method", "fdr_bh"),
            "timeout": ENRICHMENT_TIMEOUT,
        }

        if background_sites:
            query_params["background"] = background_sites

        enrichment_data = await adapter.query("kinase_analysis", **query_params)

        # Parse results
        results = _parse_kinase_results(enrichment_data)
        statistics = _compute_kinase_statistics(results, args, len(unique_genes))

        # Build response
        response_data = {
            "results": [r for r in results],
            "statistics": statistics,
            "total_phosphosites": len(phosphosites),
            "unique_genes": len(unique_genes),
        }

        # Format response
        formatter = get_formatter()
        response = formatter.format_response(
            data=response_data,
            format_type=args.get("response_format", "markdown"),
            max_chars=CHARACTER_LIMIT,
        )

        return [types.TextContent(type="text", text=response)]

    except ValueError as e:
        logger.warning(f"Validation error: {e}")
        return [types.TextContent(type="text", text=f"Error: {str(e)}")]
    except Exception as e:
        logger.error(f"Tool error: {e}", exc_info=True)
        return [types.TextContent(type="text", text=f"Error: Unexpected error occurred. {str(e)}")]


def _parse_kinase_results(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse kinase enrichment results from backend response."""
    if not data.get("success") or not data.get("results"):
        return []

    results = []
    for record in data["results"]:
        # Parse kinase entity
        kinase = {
            "name": record.get("kinase_name", "Unknown"),
            "curie": record.get("kinase_id", "unknown:unknown"),
            "namespace": record.get("kinase_namespace", "hgnc"),
            "identifier": record.get("kinase_identifier", "unknown"),
        }

        # Determine confidence level based on substrate count and evidence
        substrate_count = record.get("substrate_count", 0)
        total_substrates = record.get("total_substrates", 0)
        p_value = record.get("adjusted_p_value", 1.0)

        # Confidence heuristics:
        # - high: 5+ substrates, p < 0.01, or >20% of known substrates
        # - medium: 3-4 substrates, p < 0.05
        # - low: 1-2 substrates
        if (
            substrate_count >= 5
            or p_value < 0.01
            or (total_substrates > 0 and substrate_count / total_substrates > 0.2)
        ):
            confidence = "high"
        elif substrate_count >= 3 and p_value < 0.05:
            confidence = "medium"
        else:
            confidence = "low"

        result = {
            "kinase": kinase,
            "p_value": record.get("p_value", 1.0),
            "adjusted_p_value": record.get("adjusted_p_value", 1.0),
            "substrate_count": substrate_count,
            "total_substrates": total_substrates,
            "phosphosites": record.get("phosphosites", []),
            "prediction_confidence": record.get("confidence", confidence),
        }

        results.append(result)

    # Sort by adjusted p-value (most significant first)
    results.sort(key=lambda x: x["adjusted_p_value"])

    return results


def _compute_kinase_statistics(
    results: list[dict[str, Any]],
    args: dict[str, Any],
    total_genes: int,
) -> dict[str, Any]:
    """Compute overall kinase enrichment statistics."""
    # Count significant results
    alpha = args.get("alpha", 0.05)
    significant_results = sum(1 for r in results if r["adjusted_p_value"] <= alpha)

    return {
        "total_results": len(results),
        "significant_results": significant_results,
        "total_genes_analyzed": total_genes,
        "correction_method": args.get("correction_method", "fdr_bh"),
        "alpha": alpha,
    }


async def _handle_protein_functions_query(args: dict[str, Any]) -> list[types.TextContent]:
    """Handle protein functions query - Tool 16."""
    try:
        mode = args.get("mode")
        response_format = args.get("response_format", "markdown")

        # Route to appropriate handler based on mode
        if mode == "gene_to_activities":
            result = await _get_enzyme_activities(args)
        elif mode == "activity_to_genes":
            result = await _get_genes_for_activity(args)
        elif mode == "check_activity":
            result = await _check_enzyme_activity(args)
        elif mode == "check_function_types":
            result = await _check_function_types(args)
        else:
            return [types.TextContent(
                type="text",
                text=f"Error: Unknown query mode '{mode}'"
            )]

        # Format response
        formatter = get_formatter()
        response = formatter.format_response(
            data=result,
            format_type=response_format,
            max_chars=CHARACTER_LIMIT,
        )

        return [types.TextContent(type="text", text=response)]

    except EntityResolutionError as e:
        logger.warning(f"Entity resolution error: {e}")
        return [types.TextContent(type="text", text=f"Error: {str(e)}")]
    except Exception as e:
        logger.error(f"Tool error: {e}", exc_info=True)
        return [types.TextContent(type="text", text=f"Error: Unexpected error occurred. {str(e)}")]


# Tool 16 Mode Handlers
async def _get_enzyme_activities(args: dict[str, Any]) -> dict[str, Any]:
    """Mode: gene_to_activities - Get all enzyme activities for a specific gene."""
    gene_input = args.get("gene")
    if not gene_input:
        raise ValueError("gene parameter required for gene_to_activities mode")

    # Resolve gene identifier
    resolver = get_resolver()
    gene = await resolver.resolve_gene(gene_input)

    adapter = await get_adapter()

    # Fetch enzyme activities from backend
    activity_data = await adapter.query(
        "get_enzyme_activities",
        gene_id=gene.curie,
        timeout=STANDARD_QUERY_TIMEOUT,
    )

    # Parse activities
    activities = _parse_enzyme_activities(activity_data)

    return {
        "gene": {
            "name": gene.name,
            "curie": gene.curie,
            "namespace": gene.namespace,
            "identifier": gene.identifier,
        },
        "activities": activities,
    }


async def _get_genes_for_activity(args: dict[str, Any]) -> dict[str, Any]:
    """Mode: activity_to_genes - Find all genes with a specific enzyme activity."""
    enzyme_activity = args.get("enzyme_activity")
    if not enzyme_activity:
        raise ValueError("enzyme_activity parameter required for activity_to_genes mode")

    adapter = await get_adapter()

    # Build query parameters
    query_params = {
        "activity": enzyme_activity,
        "limit": args.get("limit", 20),
        "offset": args.get("offset", 0),
    }

    gene_data = await adapter.query(
        "get_genes_for_activity",
        **query_params,
        timeout=STANDARD_QUERY_TIMEOUT,
    )

    # Parse gene list
    genes = _parse_gene_list_protein_function(gene_data)

    # Create pagination metadata
    pagination_service = get_pagination()
    pagination = pagination_service.paginate(
        items=genes,
        total_count=gene_data.get("total_count", len(genes)),
        offset=args.get("offset", 0),
        limit=args.get("limit", 20),
    )

    return {
        "activity": enzyme_activity,
        "genes": genes,
        "pagination": pagination.model_dump(),
    }


async def _check_enzyme_activity(args: dict[str, Any]) -> dict[str, Any]:
    """Mode: check_activity - Check if a gene has a specific enzyme activity."""
    gene_input = args.get("gene")
    enzyme_activity = args.get("enzyme_activity")

    if not gene_input:
        raise ValueError("gene parameter required for check_activity mode")
    if not enzyme_activity:
        raise ValueError("enzyme_activity parameter required for check_activity mode")

    # Resolve gene identifier
    resolver = get_resolver()
    gene = await resolver.resolve_gene(gene_input)

    adapter = await get_adapter()

    # Check specific activity based on type
    activity_lower = enzyme_activity.lower()

    # Map activity names to backend check functions
    if activity_lower in ["kinase", "protein kinase"]:
        check_data = await adapter.query(
            "is_kinase",
            gene_id=gene.curie,
            timeout=STANDARD_QUERY_TIMEOUT,
        )
    elif activity_lower in ["phosphatase", "protein phosphatase"]:
        check_data = await adapter.query(
            "is_phosphatase",
            gene_id=gene.curie,
            timeout=STANDARD_QUERY_TIMEOUT,
        )
    elif activity_lower in ["transcription_factor", "transcription factor", "tf"]:
        check_data = await adapter.query(
            "is_transcription_factor",
            gene_id=gene.curie,
            timeout=STANDARD_QUERY_TIMEOUT,
        )
    else:
        # Generic activity check
        check_data = await adapter.query(
            "has_enzyme_activity",
            gene_id=gene.curie,
            activity=enzyme_activity,
            timeout=STANDARD_QUERY_TIMEOUT,
        )

    has_activity = check_data.get("result", False) if check_data.get("success") else False

    return {
        "has_activity": has_activity,
        "gene": {
            "name": gene.name,
            "curie": gene.curie,
            "namespace": gene.namespace,
            "identifier": gene.identifier,
        },
        "activity": enzyme_activity,
    }


async def _check_function_types(args: dict[str, Any]) -> dict[str, Any]:
    """Mode: check_function_types - Batch check if genes have specific function types."""
    # Determine which genes to check
    genes_to_check = []

    if args.get("genes"):
        genes_to_check = args["genes"]
    elif args.get("gene"):
        genes_to_check = [args["gene"]]
    else:
        raise ValueError("Either gene or genes parameter required for check_function_types mode")

    function_types = args.get("function_types")
    if not function_types:
        raise ValueError("function_types parameter required for check_function_types mode")

    # Resolve all gene identifiers
    resolver = get_resolver()
    resolved_genes = {}

    for gene_input in genes_to_check:
        try:
            gene = await resolver.resolve_gene(gene_input)
            resolved_genes[gene.name] = gene
        except EntityResolutionError as e:
            logger.warning(f"Could not resolve gene '{gene_input}': {e}")
            # Include unresolved genes with None value
            resolved_genes[str(gene_input)] = None

    adapter = await get_adapter()
    function_checks = {}

    # Check each function type for each gene
    for gene_name, gene in resolved_genes.items():
        if gene is None:
            # Gene could not be resolved
            function_checks[gene_name] = dict.fromkeys(function_types, False)
            continue

        gene_results = {}

        for function_type in function_types:
            function_lower = function_type.lower()

            try:
                # Map function type to backend endpoint
                if function_lower in ["kinase", "protein_kinase"]:
                    check_data = await adapter.query(
                        "is_kinase",
                        gene_id=gene.curie,
                        timeout=STANDARD_QUERY_TIMEOUT,
                    )
                elif function_lower in ["phosphatase", "protein_phosphatase"]:
                    check_data = await adapter.query(
                        "is_phosphatase",
                        gene_id=gene.curie,
                        timeout=STANDARD_QUERY_TIMEOUT,
                    )
                elif function_lower in ["transcription_factor", "transcription factor", "tf"]:
                    check_data = await adapter.query(
                        "is_transcription_factor",
                        gene_id=gene.curie,
                        timeout=STANDARD_QUERY_TIMEOUT,
                    )
                else:
                    logger.warning(f"Unknown function type: {function_type}")
                    gene_results[function_type] = False
                    continue

                has_function = (
                    check_data.get("result", False) if check_data.get("success") else False
                )
                gene_results[function_type] = has_function

            except Exception as e:
                logger.warning(f"Error checking {function_type} for {gene_name}: {e}")
                gene_results[function_type] = False

        function_checks[gene_name] = gene_results

    return {
        "function_checks": function_checks,
        "genes_checked": len(resolved_genes),
        "function_types": function_types,
    }


# Data parsing helpers for Tool 16
def _parse_enzyme_activities(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse enzyme activities from backend response."""
    if not data.get("success") or not data.get("records"):
        return []

    activities = []
    for record in data["records"]:
        activities.append(
            {
                "activity": record.get("activity", "Unknown"),
                "ec_number": record.get("ec_number"),
                "confidence": record.get("confidence", "medium"),
                "evidence_sources": record.get("evidence_sources", []),
            }
        )

    return activities


def _parse_gene_list_protein_function(data: dict[str, Any]) -> list[dict[str, Any]]:
    """Parse gene list from backend response."""
    if not data.get("success") or not data.get("records"):
        return []

    genes = []
    for record in data["records"]:
        genes.append(
            {
                "name": record.get("gene", record.get("name", "Unknown")),
                "curie": record.get("gene_id", record.get("curie", "unknown:unknown")),
                "namespace": "hgnc",
                "identifier": record.get("gene_id", record.get("identifier", "unknown")),
                "description": record.get("description"),
                "synonyms": record.get("synonyms", []),
            }
        )

    return genes


async def main():
    """Main entry point."""
    logger.info("=" * 80)
    logger.info("INDRA CoGEx MCP Server (Low-Level) v1.0.0 - All 16 Tools")
    logger.info("=" * 80)
    logger.info("Transport: stdio")
    logger.info(f"Debug mode: {settings.debug_mode}")
    logger.info(f"Character limit: {settings.character_limit:,}")
    logger.info("=" * 80)

    try:
        # Initialize backend
        await initialize_backend()

        # Run server
        async with mcp.server.stdio.stdio_server() as (read_stream, write_stream):
            await server.run(
                read_stream,
                write_stream,
                InitializationOptions(
                    server_name="cogex_mcp",
                    server_version="1.0.0",
                    capabilities=server.get_capabilities(
                        notification_options=NotificationOptions(),
                        experimental_capabilities={},
                    ),
                ),
            )

    except KeyboardInterrupt:
        logger.info("Server stopped by user")
    except Exception as e:
        logger.error(f"Server error: {e}", exc_info=True)
        sys.exit(1)
    finally:
        await cleanup_backend()


if __name__ == "__main__":
    asyncio.run(main())
